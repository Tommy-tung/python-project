{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import stackprinter\n",
    "import seaborn as sns\n",
    "from itertools import chain\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision.utils import save_image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import confusion_matrix\n",
    "stackprinter.set_excepthook(style='darkbg2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = '/Users/tommy84729/Coding/DL/ＨＷ2/data'\n",
    "fileList = os.listdir(mypath)\n",
    "fileList.remove('.DS_Store')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(mypath,filelist, height, width) : \n",
    "    data = []\n",
    "    for i in range(len(filelist)) : \n",
    "        path_=os.path.join(mypath,fileList[i])\n",
    "        img = Image.open(path_).convert(\"RGB\").resize((height,width))\n",
    "        a = np.transpose(np.array(img)).astype(np.float32)/255\n",
    "        data.append(a)\n",
    "        if (i+1)%1000 == 0 : \n",
    "            print(i)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n",
      "1999\n",
      "2999\n",
      "3999\n",
      "4999\n",
      "5999\n",
      "6999\n",
      "7999\n",
      "8999\n",
      "9999\n",
      "10999\n",
      "11999\n",
      "12999\n",
      "13999\n",
      "14999\n",
      "15999\n",
      "16999\n",
      "17999\n",
      "18999\n",
      "19999\n",
      "20999\n"
     ]
    }
   ],
   "source": [
    "height = 28\n",
    "width = 28\n",
    "data = data_preprocessing(mypath, fileList, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('/Users/tommy84729/coding/DL/ＨＷ2/data.npz', data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(8,8, figsize = (8,8)) \n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        ax[i,j].imshow(data[8*i+j])\n",
    "        ax[i,j].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "data = np.array(data)\n",
    "feature_train = torch.from_numpy(data)\n",
    "train = torch.utils.data.TensorDataset(feature_train)\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size =  height * width\n",
    "h_dim = 400\n",
    "z_dim = 20\n",
    "epoch = 10\n",
    "learning_rate = 1e-3\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module) : \n",
    "    def __init__(self, image_size = image_size , h_dim = h_dim , z_dim = z_dim) : \n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(image_size, h_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim)\n",
    "        self.fc5 = nn.Linear(h_dim, image_size)\n",
    "        \n",
    "    def encode(self, x) : \n",
    "        h = F.relu(self.fc1(x))\n",
    "        return self.fc2(h), self.fc3(h)\n",
    "    \n",
    "    def reparameterize(self, mu, log_var) : \n",
    "        std = torch.exp(log_var/2)\n",
    "        eps = torch.randn_like(std)\n",
    "        \n",
    "        return(mu + eps*std)\n",
    "    \n",
    "    def decode(self, z) : \n",
    "        h = F.relu(self.fc4(z))\n",
    "        return F.sigmoid(self.fc5(h))\n",
    "    \n",
    "    def forward(self, x) : \n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_reconst = self.decode(z)\n",
    "        return mu, log_var , x_reconst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE().to(device).float()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10/10\r"
     ]
    }
   ],
   "source": [
    "total_loss = []\n",
    "for i in range(epoch):\n",
    "    running_loss = 0\n",
    "    for  x in train_loader:\n",
    "        # Forward pass\n",
    "        x = x[0].to(device).view(-1, image_size)\n",
    "        mu,log_var, x_reconst = model(x.float())\n",
    "        reconst_loss = F.binary_cross_entropy(x_reconst, x.float(), size_average=False)\n",
    "        kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        loss = reconst_loss + kl_div.item()\n",
    "        running_loss += loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    total_loss.append(running_loss)\n",
    "    print(f'epoch: {i+1}/{epoch}', end = '\\r')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a5f78b630>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  # Save the sampled images\n",
    "    z = torch.randn(1,batch_size, z_dim).to(device)\n",
    "    out = model.decode(z).view(-1, 3, height, width)\n",
    "    save_image(out, os.path.join('/Users/tommy84729/python/DL/ＨＷ2','sampled-{}.png'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAADCAIAAAAP7/iNAAAAjElEQVR4nEXOvWpCAQzF8Z+XgoiDKBQU0U3wPfIOtkNBcHcRcRH15XyHItTJpYuD6OYHDjdwDxzyJzkkwS5KfwXLYBusg0XwE0yCaTCPKrtKfwezzG9ytomCh1JjNJM/kusYYYg2Ttjjgga6eOGIPxzwr+AXT1xz4V2lXh6oZb+f3FE+08IZnxhkvXkDn7sf1A0s6kYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x3 at 0x1A42BE7320>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray(np.transpose(data[1])*255, 'RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [3948 x 28], m2: [2352 x 400] at ../aten/src/TH/generic/THTensorMath.cpp:41",
     "output_type": "error",
     "traceback": [
      "\u001b[38;5;145mFile /Library/anaconda3/lib/python3.7/site-packages/IPython/core/\u001b[0m\u001b[1;38;5;231minteractiveshell.py\u001b[0m\u001b[38;5;145m, line 3325, in run_code\n\u001b[0m    \u001b[38;5;188m\u001b[0m\u001b[38;5;188mexec\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[38;5;188mcode_obj\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188mself.user_global_ns\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188mself.user_ns\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[38;5;145mFile \u001b[0m\u001b[1;38;5;231m<ipython-input-105-efff6ab889e5>\u001b[0m\u001b[38;5;145m, line 1, in <module>\n\u001b[0m\u001b[1;38;5;188m--> 1    \u001b[1;38;5;148m_\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;148m_\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;44mout\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m=\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;20mmodel\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[38;5;188mx.float\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[0m\u001b[1;38;5;59m    2    \u001b[1;38;5;44mout\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m=\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188mout.view\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[1;38;5;188m-\u001b[0m\u001b[38;5;188m1\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m 3\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m 28\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m 28\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[1;38;5;188m.\u001b[0m\u001b[38;5;188mfloat\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[0m\u001b[38;5;102m    ..................................................\u001b[0m\n\u001b[1;38;5;148m     _ = tensor([[-13.7474, -22.8047, -21.0376, -21.1729, -19.6787, -\n          20.0767, -15.9335,\n                  -17.8336, -22.6897, -16.1117, -21.2702, -24.6458, -\n          22.1293, -20.4836,\n                  -15.0203, -20.8876, -21.4938, -19.1705, -22.1598, -\n          11.5195],\n                 [-12.2797, -19.7853, -19.3934, -21.1498, -16.6041, -\n          18.3339, -13.4736,\n                  -16.6207, -19.2721, -15.4060, -19.3207, -19.4123, -\n          19.6210, -17.7877,\n                  -14.4506, -17.6162, -18.9175, -17.8186, -20.1002, -\n          10.9796],\n                 [-13.3836, -22.1643, -20.5568, -21.2...\n\u001b[0m\u001b[1;38;5;44m     out = tensor([[[[0.6661, 0.6578, 0.8128,  ..., 0.3227, 0.5322, 0.3\n            156],\n                     [0.4023, 0.5845, 0.3102,  ..., 0.6339, 0.2895, 0.4\n            230],\n                     [0.6041, 0.2442, 0.3608,  ..., 0.4298, 0.4333, 0.5\n            336],\n                     ...,\n                     [0.2284, 0.3364, 0.2573,  ..., 0.2191, 0.3047, 0.2\n            637],\n                     [0.3430, 0.2078, 0.1704,  ..., 0.1767, 0.1724, 0.3\n            288],\n                     [0.2840, 0.3758, 0.5548,  ..., 0.2594, 0.2867, 0.4\n            627]],\n           \n                    [[0.3304, 0.3150, 0.4087,  ..., 0.2912, 0.5367, 0.4\n            542],\n                     [0.5423, 0....\n\u001b[0m\u001b[1;38;5;20m     model = VAE(\n               (fc1): Linear(in_features=2352, out_features=400, bias=Tru\n              e)\n               (fc2): Linear(in_features=400, out_features=20, bias=True)\n               (fc3): Linear(in_features=400, out_features=20, bias=True)\n               (fc4): Linear(in_features=20, out_features=400, bias=True)\n               (fc5): Linear(in_features=400, out_features=2352, bias=Tru\n              e)\n             )\n\u001b[0m\u001b[38;5;102m    ..................................................\u001b[0m\n\n\u001b[38;5;145mFile /Library/anaconda3/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;38;5;231mmodule.py\u001b[0m\u001b[38;5;145m, line 550, in __call__\n\u001b[0m\u001b[1;38;5;59m    540  \u001b[38;5;188m\u001b[0m\u001b[1;38;5;188mdef\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188m__call__\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[38;5;20mself\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m*\u001b[0m\u001b[1;38;5;76minput\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m**\u001b[0m\u001b[1;38;5;44mkwargs\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[1;38;5;188m:\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[0m\u001b[38;5;102m (...)\n\u001b[0m\u001b[1;38;5;59m    546  \u001b[38;5;188m            \u001b[0m\u001b[1;38;5;76minput\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m=\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188mresult\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[0m\u001b[1;38;5;59m    547  \u001b[38;5;188m    \u001b[0m\u001b[1;38;5;188mif\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188mtorch._C._get_tracing_state\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[1;38;5;188m:\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[0m\u001b[1;38;5;59m    548  \u001b[38;5;188m        \u001b[0m\u001b[38;5;188mresult\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m=\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;184mself._slow_forward\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[1;38;5;188m*\u001b[0m\u001b[1;38;5;76minput\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m**\u001b[0m\u001b[1;38;5;44mkwargs\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[0m\u001b[1;38;5;59m    549  \u001b[38;5;188m    \u001b[0m\u001b[1;38;5;188melse\u001b[0m\u001b[1;38;5;188m:\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[0m\u001b[1;38;5;188m--> 550  \u001b[38;5;188m        \u001b[0m\u001b[38;5;188mresult\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m=\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;32mself.forward\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[1;38;5;188m*\u001b[0m\u001b[1;38;5;76minput\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m**\u001b[0m\u001b[1;38;5;44mkwargs\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[0m\u001b[1;38;5;59m    551  \u001b[38;5;188m    \u001b[0m\u001b[1;38;5;188mfor\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188mhook\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188min\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188mself._forward_hooks.values\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[1;38;5;188m:\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[0m\u001b[38;5;102m    ..................................................\u001b[0m\n\u001b[38;5;20m     self = VAE(\n              (fc1): Linear(in_features=2352, out_features=400, bias=Tru\n             e)\n              (fc2): Linear(in_features=400, out_features=20, bias=True)\n              (fc3): Linear(in_features=400, out_features=20, bias=True)\n              (fc4): Linear(in_features=20, out_features=400, bias=True)\n              (fc5): Linear(in_features=400, out_features=2352, bias=Tru\n             e)\n            )\n\u001b[0m\u001b[1;38;5;76m     input = (\n              tensor([[[[0.7098, 0.3176, 0.6549,  ..., 0.2314, 0.4588, 0.\n              2941],\n                        [0.0392, 0.2471, 0.4706,  ..., 0.5608, 0.5020, 0.\n              1451],\n                        [0.3255, 0.9961, 0.6431,  ..., 0.4314, 0.1294, 0.\n              3490],\n                        ...,\n                        [1.0000, 0.9137, 0.9922,  ..., 0.6314, 1.0000, 0.\n              8275],\n                        [0.7098, 0.7647, 0.5647,  ..., 0.6784, 0.3176, 0.\n              6353],\n                        [1.0000, 0.6000, 0.5961,  ..., 0.1490, 0.3255, 0.\n              4118]],\n              \n                       [[0.1059, 0.4196, 0.3686,  ..., 0.7412, 0.9451, 0.\n              7686],...\n\u001b[0m\u001b[1;38;5;44m     kwargs = {}\n\u001b[0m\u001b[38;5;184m     self._slow_forward = <method 'Module._slow_forward' of VAE(\n                            (fc1): Linear(in_features=2352, out_features=400, bias=Tru\n                           e)\n                            (fc2): Linear(in_features=400, out_features=20, bias=True)\n                            (fc3): Linear(in_features=400, out_features=20, bias=True)\n                            (fc4): Linear(in_features=20, out_features=400, bias=True)\n                            (fc5): Linear(in_features=400, out_features=2352, bias=Tru\n                           e)\n                          ) module.py:521>\n\u001b[0m\u001b[1;38;5;32m     self.forward = <method 'VAE.forward' of VAE(\n                      (fc1): Linear(in_features=2352, out_features=400, bias=Tru\n                     e)\n                      (fc2): Linear(in_features=400, out_features=20, bias=True)\n                      (fc3): Linear(in_features=400, out_features=20, bias=True)\n                      (fc4): Linear(in_features=20, out_features=400, bias=True)\n                      (fc5): Linear(in_features=400, out_features=2352, bias=Tru\n                     e)\n                    ) <ipython-input-97-e36438a76042>:24>\n\u001b[0m\u001b[38;5;102m    ..................................................\u001b[0m\n\n\u001b[38;5;145mFile \u001b[0m\u001b[1;38;5;231m<ipython-input-97-e36438a76042>\u001b[0m\u001b[38;5;145m, line 25, in forward\n\u001b[0m\u001b[1;38;5;59m    24   \u001b[38;5;188m\u001b[0m\u001b[1;38;5;188mdef\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188mforward\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[38;5;20mself\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;56mx\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m:\u001b[0m\u001b[38;5;188m \n\u001b[0m\u001b[0m\u001b[1;38;5;188m--> 25   \u001b[38;5;188m    \u001b[0m\u001b[1;38;5;76mmu\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;40mlog_var\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m=\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;178mself.encode\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[1;38;5;56mx\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[0m\u001b[1;38;5;59m    26   \u001b[38;5;188m    \u001b[0m\u001b[38;5;44mz\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m=\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;26mself.reparameterize\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[1;38;5;76mmu\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;40mlog_var\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[0m\u001b[38;5;102m    ..................................................\u001b[0m\n\u001b[38;5;20m     self = VAE(\n              (fc1): Linear(in_features=2352, out_features=400, bias=Tru\n             e)\n              (fc2): Linear(in_features=400, out_features=20, bias=True)\n              (fc3): Linear(in_features=400, out_features=20, bias=True)\n              (fc4): Linear(in_features=20, out_features=400, bias=True)\n              (fc5): Linear(in_features=400, out_features=2352, bias=Tru\n             e)\n            )\n\u001b[0m\u001b[1;38;5;56m     x = tensor([[[[0.7098, 0.3176, 0.6549,  ..., 0.2314, 0.4588, 0.2\n          941],\n                   [0.0392, 0.2471, 0.4706,  ..., 0.5608, 0.5020, 0.1\n          451],\n                   [0.3255, 0.9961, 0.6431,  ..., 0.4314, 0.1294, 0.3\n          490],\n                   ...,\n                   [1.0000, 0.9137, 0.9922,  ..., 0.6314, 1.0000, 0.8\n          275],\n                   [0.7098, 0.7647, 0.5647,  ..., 0.6784, 0.3176, 0.6\n          353],\n                   [1.0000, 0.6000, 0.5961,  ..., 0.1490, 0.3255, 0.4\n          118]],\n         \n                  [[0.1059, 0.4196, 0.3686,  ..., 0.7412, 0.9451, 0.7\n          686],\n                   [0.6902, 0....\n\u001b[0m\u001b[1;38;5;76m     mu = tensor([[-1.4644, -3.2240, -0.1164, -1.7011,  1.3009, -0.490\n           1,  1.4778,  2.8152,\n                   -0.0595, -1.9842,  0.3208,  0.3149, -0.0181,  0.461\n           8, -3.7157,  0.4743,\n                    1.2177, -0.5090,  1.3279,  0.5278],\n                  [ 0.4690, -3.6817, -0.5885, -2.4305,  0.4516,  0.258\n           3,  0.1944,  3.6261,\n                    0.1943, -3.4994,  2.1444, -1.1271, -1.1929, -0.710\n           1, -0.1909,  0.1948,\n                   -0.4209,  2.1336, -1.7618,  0.0390],\n                  [-2.5721, -3.3937, -1.3156, -0.2423,  3.0457, -1.584\n           6,  1.1260,  0.5955,...\n\u001b[0m\u001b[1;38;5;40m     log_var = tensor([[-13.9725, -22.7942, -21.0741, -21.2344, -19.7590, -\n                20.1534, -15.9002,\n                        -17.9579, -22.8093, -16.0888, -21.3706, -24.6740, -\n                22.2391, -20.4569,\n                        -15.0183, -20.9482, -21.5849, -19.2692, -22.2261, -\n                11.6206],\n                       [-12.4487, -19.8028, -19.4328, -21.2080, -16.6869, -\n                18.3926, -13.4515,\n                        -16.7002, -19.3837, -15.4199, -19.4241, -19.4828, -\n                19.7131, -17.8084,\n                        -14.4667, -17.6877, -18.9671, -17.9154, -20.1818, -\n                11.0768],\n                       [-13.6008, -22.1201, -20.5773, -21.3...\n\u001b[0m\u001b[1;38;5;178m     self.encode = <method 'VAE.encode' of VAE(\n                     (fc1): Linear(in_features=2352, out_features=400, bias=Tru\n                    e)\n                     (fc2): Linear(in_features=400, out_features=20, bias=True)\n                     (fc3): Linear(in_features=400, out_features=20, bias=True)\n                     (fc4): Linear(in_features=20, out_features=400, bias=True)\n                     (fc5): Linear(in_features=400, out_features=2352, bias=Tru\n                    e)\n                   ) <ipython-input-97-e36438a76042>:10>\n\u001b[0m\u001b[38;5;44m     z = tensor([[[-0.8137,  0.7375, -1.2675,  ..., -0.9067, -0.4767,\n           -2.2604],\n                  [-0.3004, -0.2652,  0.5045,  ..., -0.5620, -1.2513,\n            1.3448],\n                  [-1.2008, -0.2812,  1.6149,  ..., -1.1581,  1.0894,\n           -0.5494],\n                  ...,\n                  [ 0.0340, -0.4674, -1.8836,  ..., -2.1004,  0.7632,\n            0.3793],\n                  [ 0.2591,  1.5602, -1.6494,  ...,  0.3492, -0.7350,\n           -0.1066],\n                  [ 0.6601,  1.8076,  0.5675,  ...,  0.1949, -0.2704,\n            0.3333]]])\n\u001b[0m\u001b[38;5;26m     self.reparameterize = <method 'VAE.reparameterize' of VAE(\n                             (fc1): Linear(in_features=2352, out_features=400, bias=Tru\n                            e)\n                             (fc2): Linear(in_features=400, out_features=20, bias=True)\n                             (fc3): Linear(in_features=400, out_features=20, bias=True)\n                             (fc4): Linear(in_features=20, out_features=400, bias=True)\n                             (fc5): Linear(in_features=400, out_features=2352, bias=Tru\n                            e)\n                           ) <ipython-input-97-e36438a76042>:14>\n\u001b[0m\u001b[38;5;102m    ..................................................\u001b[0m\n\n\u001b[38;5;145mFile \u001b[0m\u001b[1;38;5;231m<ipython-input-97-e36438a76042>\u001b[0m\u001b[38;5;145m, line 11, in encode\n\u001b[0m\u001b[1;38;5;59m    10   \u001b[38;5;188m\u001b[0m\u001b[1;38;5;188mdef\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188mencode\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[38;5;20mself\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;56mx\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m:\u001b[0m\u001b[38;5;188m \n\u001b[0m\u001b[0m\u001b[1;38;5;188m--> 11   \u001b[38;5;188m    \u001b[0m\u001b[38;5;188mh\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m=\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;178mF.relu\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[1;38;5;148mself.fc1\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[1;38;5;56mx\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[0m\u001b[1;38;5;59m    12   \u001b[38;5;188m    \u001b[0m\u001b[1;38;5;188mreturn\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;26mself.fc2\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[38;5;188mh\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;184mself.fc3\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[38;5;188mh\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[0m\u001b[38;5;102m    ..................................................\u001b[0m\n\u001b[38;5;20m     self = VAE(\n              (fc1): Linear(in_features=2352, out_features=400, bias=Tru\n             e)\n              (fc2): Linear(in_features=400, out_features=20, bias=True)\n              (fc3): Linear(in_features=400, out_features=20, bias=True)\n              (fc4): Linear(in_features=20, out_features=400, bias=True)\n              (fc5): Linear(in_features=400, out_features=2352, bias=Tru\n             e)\n            )\n\u001b[0m\u001b[1;38;5;56m     x = tensor([[[[0.7098, 0.3176, 0.6549,  ..., 0.2314, 0.4588, 0.2\n          941],\n                   [0.0392, 0.2471, 0.4706,  ..., 0.5608, 0.5020, 0.1\n          451],\n                   [0.3255, 0.9961, 0.6431,  ..., 0.4314, 0.1294, 0.3\n          490],\n                   ...,\n                   [1.0000, 0.9137, 0.9922,  ..., 0.6314, 1.0000, 0.8\n          275],\n                   [0.7098, 0.7647, 0.5647,  ..., 0.6784, 0.3176, 0.6\n          353],\n                   [1.0000, 0.6000, 0.5961,  ..., 0.1490, 0.3255, 0.4\n          118]],\n         \n                  [[0.1059, 0.4196, 0.3686,  ..., 0.7412, 0.9451, 0.7\n          686],\n                   [0.6902, 0....\n\u001b[0m\u001b[1;38;5;178m     F.relu = <function 'relu' functional.py:1050>\n\u001b[0m\u001b[1;38;5;148m     self.fc1 = Linear(in_features=2352, out_features=400, bias=True)\n\u001b[0m\u001b[38;5;26m     self.fc2 = Linear(in_features=400, out_features=20, bias=True)\n\u001b[0m\u001b[38;5;184m     self.fc3 = Linear(in_features=400, out_features=20, bias=True)\n\u001b[0m\u001b[38;5;102m    ..................................................\u001b[0m\n\n\u001b[38;5;145mFile /Library/anaconda3/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;38;5;231mmodule.py\u001b[0m\u001b[38;5;145m, line 550, in __call__\n\u001b[0m\u001b[1;38;5;59m    540  \u001b[38;5;188m\u001b[0m\u001b[1;38;5;188mdef\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188m__call__\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[38;5;148mself\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m*\u001b[0m\u001b[1;38;5;20minput\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m**\u001b[0m\u001b[1;38;5;112mkwargs\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[1;38;5;188m:\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[0m\u001b[38;5;102m (...)\n\u001b[0m\u001b[1;38;5;59m    546  \u001b[38;5;188m            \u001b[0m\u001b[1;38;5;20minput\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m=\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188mresult\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[0m\u001b[1;38;5;59m    547  \u001b[38;5;188m    \u001b[0m\u001b[1;38;5;188mif\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188mtorch._C._get_tracing_state\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[1;38;5;188m:\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[0m\u001b[1;38;5;59m    548  \u001b[38;5;188m        \u001b[0m\u001b[38;5;188mresult\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m=\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;178mself._slow_forward\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[1;38;5;188m*\u001b[0m\u001b[1;38;5;20minput\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m**\u001b[0m\u001b[1;38;5;112mkwargs\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[0m\u001b[1;38;5;59m    549  \u001b[38;5;188m    \u001b[0m\u001b[1;38;5;188melse\u001b[0m\u001b[1;38;5;188m:\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[0m\u001b[1;38;5;188m--> 550  \u001b[38;5;188m        \u001b[0m\u001b[38;5;188mresult\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m=\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;112mself.forward\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[1;38;5;188m*\u001b[0m\u001b[1;38;5;20minput\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m**\u001b[0m\u001b[1;38;5;112mkwargs\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[0m\u001b[1;38;5;59m    551  \u001b[38;5;188m    \u001b[0m\u001b[1;38;5;188mfor\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188mhook\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188min\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188mself._forward_hooks.values\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[1;38;5;188m:\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[0m\u001b[38;5;102m    ..................................................\u001b[0m\n\u001b[38;5;148m     self = Linear(in_features=2352, out_features=400, bias=True)\n\u001b[0m\u001b[1;38;5;20m     input = (\n              tensor([[[[0.7098, 0.3176, 0.6549,  ..., 0.2314, 0.4588, 0.\n              2941],\n                        [0.0392, 0.2471, 0.4706,  ..., 0.5608, 0.5020, 0.\n              1451],\n                        [0.3255, 0.9961, 0.6431,  ..., 0.4314, 0.1294, 0.\n              3490],\n                        ...,\n                        [1.0000, 0.9137, 0.9922,  ..., 0.6314, 1.0000, 0.\n              8275],\n                        [0.7098, 0.7647, 0.5647,  ..., 0.6784, 0.3176, 0.\n              6353],\n                        [1.0000, 0.6000, 0.5961,  ..., 0.1490, 0.3255, 0.\n              4118]],\n              \n                       [[0.1059, 0.4196, 0.3686,  ..., 0.7412, 0.9451, 0.\n              7686],...\n\u001b[0m\u001b[1;38;5;112m     kwargs = {}\n\u001b[0m\u001b[38;5;178m     self._slow_forward = <method 'Module._slow_forward' of Linear(in_features=2352, o\n                           ut_features=400, bias=True) module.py:521>\n\u001b[0m\u001b[1;38;5;112m     self.forward = <method 'Linear.forward' of Linear(in_features=2352, out_fea\n                     tures=400, bias=True) linear.py:86>\n\u001b[0m\u001b[38;5;102m    ..................................................\u001b[0m\n\n\u001b[38;5;145mFile /Library/anaconda3/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;38;5;231mlinear.py\u001b[0m\u001b[38;5;145m, line 87, in forward\n\u001b[0m\u001b[1;38;5;59m    86   \u001b[38;5;188m\u001b[0m\u001b[1;38;5;188mdef\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188mforward\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[38;5;148mself\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;56minput\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[1;38;5;188m:\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[0m\u001b[1;38;5;188m--> 87   \u001b[38;5;188m    \u001b[0m\u001b[1;38;5;188mreturn\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;148mF.linear\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[1;38;5;56minput\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;32mself.weight\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;184mself.bias\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[0m\u001b[38;5;102m    ..................................................\u001b[0m\n\u001b[38;5;148m     self = Linear(in_features=2352, out_features=400, bias=True)\n\u001b[0m\u001b[1;38;5;56m     input = tensor([[[[0.7098, 0.3176, 0.6549,  ..., 0.2314, 0.4588, 0.2\n              941],\n                       [0.0392, 0.2471, 0.4706,  ..., 0.5608, 0.5020, 0.1\n              451],\n                       [0.3255, 0.9961, 0.6431,  ..., 0.4314, 0.1294, 0.3\n              490],\n                       ...,\n                       [1.0000, 0.9137, 0.9922,  ..., 0.6314, 1.0000, 0.8\n              275],\n                       [0.7098, 0.7647, 0.5647,  ..., 0.6784, 0.3176, 0.6\n              353],\n                       [1.0000, 0.6000, 0.5961,  ..., 0.1490, 0.3255, 0.4\n              118]],\n             \n                      [[0.1059, 0.4196, 0.3686,  ..., 0.7412, 0.9451, 0.7\n              686],\n                       [0.6902, 0....\n\u001b[0m\u001b[1;38;5;148m     F.linear = <function 'linear' functional.py:1591>\n\u001b[0m\u001b[1;38;5;32m     self.weight = Parameter containing:\n                   tensor([[-0.0026,  0.0106, -0.0194,  ...,  0.0098, -0.0064, \n                     0.0112],\n                           [-0.0169, -0.0009,  0.0004,  ..., -0.0129, -0.0117, \n                    -0.0008],\n                           [-0.0104, -0.0252,  0.0005,  ..., -0.0138, -0.0265, \n                     0.0088],\n                           ...,\n                           [-0.0046, -0.0011, -0.0231,  ...,  0.0003, -0.0064, \n                     0.0092],\n                           [-0.0198,  0.0007, -0.0107,  ..., -0.0056,  0.0069, \n                     0.0021],\n                           [ 0.0127,  0.0134,  0.0090,  ...,  0.0005,  0.0043, \n                    -0.0152]],\n                          requires_grad=True)\n\u001b[0m\u001b[1;38;5;184m     self.bias = Parameter containing:\n                 tensor([ 2.3376e-03, -2.0395e-02, -1.1075e-02, -2.3832e-02, \n                  -2.5396e-02,\n                         -7.2462e-03, -1.9998e-01, -9.0464e-02,  1.1588e-02, \n                   1.1897e-02,\n                          1.1552e-02, -1.0661e-02, -1.7611e-01,  1.0849e-02, \n                  -1.8334e-01,\n                          4.2183e-03, -1.9587e-01, -1.6717e-01, -8.9086e-02, \n                   9.8578e-02,\n                         -1.0959e-02, -9.3863e-03, -1.9992e-02,  5.1720e-02, \n                  -1.3779e-01,\n                         -1.3988e-01, -1.3461e-02, -1.3819e-02, -6.8905e-03, \n                   6.6226e-03,\n                          4.6313e-03, -1.9408e-01, -9.699...\n\u001b[0m\u001b[38;5;102m    ..................................................\u001b[0m\n\n\u001b[38;5;145mFile /Library/anaconda3/lib/python3.7/site-packages/torch/nn/\u001b[0m\u001b[1;38;5;231mfunctional.py\u001b[0m\u001b[38;5;145m, line 1612, in linear\n\u001b[0m\u001b[1;38;5;59m    1591  \u001b[1;38;5;188mdef\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188mlinear\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[38;5;56minput\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;32mweight\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;184mbias\u001b[0m\u001b[1;38;5;188m=\u001b[0m\u001b[1;38;5;188mNone\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[1;38;5;188m:\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[0m\u001b[38;5;102m (...)\n\u001b[0m\u001b[1;38;5;59m    1608  \u001b[38;5;188m    \u001b[0m\u001b[1;38;5;188mif\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188minput.dim\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m==\u001b[0m\u001b[38;5;188m 2 \u001b[0m\u001b[1;38;5;188mand\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;184mbias\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188mis\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188mnot\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188mNone\u001b[0m\u001b[1;38;5;188m:\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[0m\u001b[1;38;5;59m    1609  \u001b[38;5;188m        \u001b[0m\u001b[38;5;59m# fused op is marginally faster\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[0m\u001b[1;38;5;59m    1610  \u001b[38;5;188m        \u001b[0m\u001b[38;5;188mret\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m=\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188mtorch.addmm\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[38;5;184mbias\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;56minput\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188mweight.t\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[0m\u001b[1;38;5;59m    1611  \u001b[38;5;188m    \u001b[0m\u001b[1;38;5;188melse\u001b[0m\u001b[1;38;5;188m:\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[0m\u001b[1;38;5;188m--> 1612  \u001b[38;5;188m        \u001b[0m\u001b[38;5;188moutput\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m=\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188minput.matmul\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[38;5;188mweight.t\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[0m\u001b[1;38;5;59m    1613  \u001b[38;5;188m        \u001b[0m\u001b[1;38;5;188mif\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;184mbias\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188mis\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188mnot\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188mNone\u001b[0m\u001b[1;38;5;188m:\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[0m\u001b[38;5;102m    ..................................................\u001b[0m\n\u001b[38;5;56m     input = tensor([[[[0.7098, 0.3176, 0.6549,  ..., 0.2314, 0.4588, 0.2\n              941],\n                       [0.0392, 0.2471, 0.4706,  ..., 0.5608, 0.5020, 0.1\n              451],\n                       [0.3255, 0.9961, 0.6431,  ..., 0.4314, 0.1294, 0.3\n              490],\n                       ...,\n                       [1.0000, 0.9137, 0.9922,  ..., 0.6314, 1.0000, 0.8\n              275],\n                       [0.7098, 0.7647, 0.5647,  ..., 0.6784, 0.3176, 0.6\n              353],\n                       [1.0000, 0.6000, 0.5961,  ..., 0.1490, 0.3255, 0.4\n              118]],\n             \n                      [[0.1059, 0.4196, 0.3686,  ..., 0.7412, 0.9451, 0.7\n              686],\n                       [0.6902, 0....\n\u001b[0m\u001b[38;5;32m     weight = Parameter containing:\n              tensor([[-0.0026,  0.0106, -0.0194,  ...,  0.0098, -0.0064, \n                0.0112],\n                      [-0.0169, -0.0009,  0.0004,  ..., -0.0129, -0.0117, \n               -0.0008],\n                      [-0.0104, -0.0252,  0.0005,  ..., -0.0138, -0.0265, \n                0.0088],\n                      ...,\n                      [-0.0046, -0.0011, -0.0231,  ...,  0.0003, -0.0064, \n                0.0092],\n                      [-0.0198,  0.0007, -0.0107,  ..., -0.0056,  0.0069, \n                0.0021],\n                      [ 0.0127,  0.0134,  0.0090,  ...,  0.0005,  0.0043, \n               -0.0152]],\n                     requires_grad=True)\n\u001b[0m\u001b[38;5;184m     bias = Parameter containing:\n            tensor([ 2.3376e-03, -2.0395e-02, -1.1075e-02, -2.3832e-02, \n             -2.5396e-02,\n                    -7.2462e-03, -1.9998e-01, -9.0464e-02,  1.1588e-02, \n              1.1897e-02,\n                     1.1552e-02, -1.0661e-02, -1.7611e-01,  1.0849e-02, \n             -1.8334e-01,\n                     4.2183e-03, -1.9587e-01, -1.6717e-01, -8.9086e-02, \n              9.8578e-02,\n                    -1.0959e-02, -9.3863e-03, -1.9992e-02,  5.1720e-02, \n             -1.3779e-01,\n                    -1.3988e-01, -1.3461e-02, -1.3819e-02, -6.8905e-03, \n              6.6226e-03,\n                     4.6313e-03, -1.9408e-01, -9.699...\n\u001b[0m\u001b[38;5;102m    ..................................................\u001b[0m\n\n---- (full traceback above) ----\n\u001b[38;5;145mFile /Library/anaconda3/lib/python3.7/site-packages/IPython/core/\u001b[0m\u001b[1;38;5;231minteractiveshell.py\u001b[0m\u001b[38;5;145m, line 3325, in run_code\n\u001b[0m    \u001b[38;5;188m\u001b[0m\u001b[38;5;188mexec\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[38;5;188mcode_obj\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188mself.user_global_ns\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188mself.user_ns\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[38;5;145mFile \u001b[0m\u001b[1;38;5;231m<ipython-input-105-efff6ab889e5>\u001b[0m\u001b[38;5;145m, line 1, in <module>\n\u001b[0m    \u001b[38;5;188m_\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188m_\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188mout\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m=\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188mmodel\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[38;5;188mx.float\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[38;5;145mFile /Library/anaconda3/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;38;5;231mmodule.py\u001b[0m\u001b[38;5;145m, line 550, in __call__\n\u001b[0m    \u001b[38;5;188m\u001b[0m\u001b[38;5;188mresult\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m=\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188mself.forward\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[1;38;5;188m*\u001b[0m\u001b[38;5;188minput\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m**\u001b[0m\u001b[38;5;188mkwargs\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[38;5;145mFile \u001b[0m\u001b[1;38;5;231m<ipython-input-97-e36438a76042>\u001b[0m\u001b[38;5;145m, line 25, in forward\n\u001b[0m    \u001b[38;5;188m\u001b[0m\u001b[38;5;188mmu\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188mlog_var\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m=\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188mself.encode\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[38;5;188mx\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[38;5;145mFile \u001b[0m\u001b[1;38;5;231m<ipython-input-97-e36438a76042>\u001b[0m\u001b[38;5;145m, line 11, in encode\n\u001b[0m    \u001b[38;5;188m\u001b[0m\u001b[38;5;188mh\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m=\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188mF.relu\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[38;5;188mself.fc1\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[38;5;188mx\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[38;5;145mFile /Library/anaconda3/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;38;5;231mmodule.py\u001b[0m\u001b[38;5;145m, line 550, in __call__\n\u001b[0m    \u001b[38;5;188m\u001b[0m\u001b[38;5;188mresult\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m=\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188mself.forward\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[1;38;5;188m*\u001b[0m\u001b[38;5;188minput\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m**\u001b[0m\u001b[38;5;188mkwargs\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[38;5;145mFile /Library/anaconda3/lib/python3.7/site-packages/torch/nn/modules/\u001b[0m\u001b[1;38;5;231mlinear.py\u001b[0m\u001b[38;5;145m, line 87, in forward\n\u001b[0m    \u001b[38;5;188m\u001b[0m\u001b[1;38;5;188mreturn\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188mF.linear\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[38;5;188minput\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188mself.weight\u001b[0m\u001b[1;38;5;188m,\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188mself.bias\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[38;5;188m\n\u001b[0m\u001b[38;5;145mFile /Library/anaconda3/lib/python3.7/site-packages/torch/nn/\u001b[0m\u001b[1;38;5;231mfunctional.py\u001b[0m\u001b[38;5;145m, line 1612, in linear\n\u001b[0m    \u001b[38;5;188m\u001b[0m\u001b[38;5;188moutput\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[1;38;5;188m=\u001b[0m\u001b[38;5;188m \u001b[0m\u001b[38;5;188minput.matmul\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[38;5;188mweight.t\u001b[0m\u001b[1;38;5;188m(\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[1;38;5;188m)\u001b[0m\u001b[38;5;188m\n\u001b[0m\n\u001b[1;38;5;160mRuntimeError: \u001b[0m\u001b[1;38;5;160msize mismatch, m1: [3948 x 28], m2: [2352 x 400] at ../aten/src/TH/generic/THTensorMath.cpp:41\u001b[0m"
     ]
    }
   ],
   "source": [
    " _ , _ , out = model(x.float())\n",
    "out = out.view(-1, 3, 28, 28).float()\n",
    "x = x.view(-1, 3, 28, 28).float()\n",
    "save_image(out, os.path.join('/Users/tommy84729/python/DL/ＨＷ2','compare_model-{}.png'.format(epoch+1)))\n",
    "save_image(x, os.path.join('/Users/tommy84729/python/DL/ＨＷ2','compare_x-{}.png'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
